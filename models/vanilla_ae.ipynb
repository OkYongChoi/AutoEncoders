{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoders\n",
    "\n",
    "Autoencoder is an unsupervised learning method that uses neural networks for representation learning tasks. The key to autoencoders is to build a neural network that places a bottleneck in the network to create a compressed knowledge representation of the original input data. Compression and subsequent reconstruction will be very difficult if the characteristics of the input data are independent of each other. However, if there is a correlation between input features, it can be learned and used when input through the network bottleneck. In other words, the bottleneck serves to limit the amount of information that can pass through the entire network, leading to learned compression of the input data.\n",
    "\n",
    "They are a type of an unsupervised learning methods. In detail, they are trained by supervised learning methods, referred to as self-supervised.\n",
    "\n",
    "Dataset: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "img_shape = (28, 28) # 28*28 for MNIST\n",
    "input_dim  = 784  # 28*28 for MNIST\n",
    "hidden_dim = 128\n",
    "latent_dim = 3\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "n_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "loader_kwargs = {'num_workers': os.cpu_count()//2, 'pin_memory': True} \n",
    "\n",
    "train_data = datasets.MNIST(root=data_path,  train=True,download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root=data_path, train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False, **loader_kwargs)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, **loader_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0: \"T-Shirt\",\n",
    "1: \"Trouser\",\n",
    "2: \"Pullover\",\n",
    "3: \"Dress\",\n",
    "4: \"Coat\",\n",
    "5: \"Sandal\",\n",
    "6: \"Shirt\",\n",
    "7: \"Sneaker\",\n",
    "8: \"Bag\",\n",
    "9: \"Ankle Boot\",\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Model\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(AutoEncoder,self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(True), \n",
    "            nn.Linear(hidden_dim, latent_dim))\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(True), \n",
    "            nn.Linear(hidden_dim, input_dim), nn.Tanh())\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "model = AutoEncoder(input_dim, hidden_dim, latent_dim).to(device)\n",
    "\n",
    "def tanh_to_img(x): \n",
    "    x = (x + 1)*0.5\n",
    "    x = x.view(batch_size, 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_dir = 'ae_images'\n",
    "os.makedirs(saved_dir, exist_ok= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, loss:0.2148\n",
      "epoch: 2/10, loss:0.2129\n",
      "epoch: 3/10, loss:0.2109\n",
      "epoch: 4/10, loss:0.2096\n",
      "epoch: 5/10, loss:0.2088\n",
      "epoch: 6/10, loss:0.2081\n",
      "epoch: 7/10, loss:0.2079\n",
      "epoch: 8/10, loss:0.2076\n",
      "epoch: 9/10, loss:0.2072\n",
      "epoch: 10/10, loss:0.2070\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        img, label = data\n",
    "        img = img.view(batch_size, -1)\n",
    "        img = img.to(device)\n",
    "\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 1 == 0:\n",
    "        output = tanh_to_img(output.data)\n",
    "        save_image(output[:25], f\"{saved_dir}/{epoch+1}.png\", nrow=5, normalize=True)\n",
    "            \n",
    "    # ===== log =====\n",
    "    print(f'epoch: {epoch+1}/{n_epochs}, loss:{loss.item() :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
