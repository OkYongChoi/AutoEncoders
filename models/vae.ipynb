{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Auto-Encoder (VAE)\n",
    "\n",
    "Diederik P Kingma, and Max Welling. Auto-Encoding Variational Bayes. 2013. [https://arxiv.org/abs/1312.6114]\n",
    "\n",
    "VAE differs from autoencoder as follows.\n",
    " - VAE is a probabilistic autoencoder. That is, even after learning is over, the output is partially determined by chance.\n",
    " - VAE is a generative autoencoder and can generate new samples, such as those sampled from the training dataset.  \n",
    "\n",
    "Dataset: CIFAR10\n",
    "\n",
    "Will implement the VAE with the convolutional neural network (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A VAE embeds the input features in the low dimensional latent space with the probabilistic encoder $q_{\\phi}(z|x)$ and reconstruct the original input from the latent embedding with the probabilistic decoder $p_{\\theta}(x|z)$.\n",
    "\n",
    "The goal is to maximize the marginal likelihood of reconstructed input data $x^{(1)}, ..., x^{(N)}$ which is composed of a sum over the marginal likelihoods of individual datapoints.\n",
    "$$\\log p_{\\theta}(x^{(1)}, ..., x^{(N)}) = \\sum_{i=1}^{N}\\log p_{\\theta}(x^{(i)})$$\n",
    "\n",
    "The individual marginal likelihood can be written as\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\log p_\\theta (x^{(i)}) &= \\mathbb{E}_{z \\sim q_\\phi (x^{(i)})}\\left[\\log p_\\theta (x^{(i)})\\right]  \\\\\n",
    "                        &= \\mathbb{E}_{z} \\left[\\log \\frac{p_\\theta (x^{(i)}|z)p_\\theta (x)}{p_\\theta (z|x^{(i)})}\\right]\\\\\n",
    "                        &= \\mathbb{E}_{z} \\left[\\log \\left( \\frac{p_\\theta (x^{(i)}|z)p_\\theta (x)}{p_\\theta (z|x^{(i)})}\n",
    "                                \\cdot \\frac{q_\\phi (z|x^{(i)})}{q_\\phi (z|x^{(i)})} \\right) \\right]  \\\\\n",
    "                        &= \\mathbb{E}_{z} \\left[\\log  p_\\theta (x^{(i)}|z) \\right] \n",
    "                        - \\mathbb{E}_{z} \\left[\\log \\frac{q_\\phi (z|x^{(i)})}{p_\\theta (z)} \\right] \n",
    "                        + \\mathbb{E}_{z} \\left[\\log \\frac{q_\\phi (z|x^{(i)})}{p_\\theta (z|x^{(i)})} \\right]\n",
    "                        \\\\\n",
    "                        &= \\mathbb{E}_{z} \\left[\\log  p_\\theta (x^{(i)}|z) \\right]\n",
    "                        - D_{KL} \\left(q_\\phi (z|x^{(i)}||p_\\theta (z)) \\right)\n",
    "                        + D_{KL} \\left(q_\\phi (z|x^{(i)}||p_\\theta (z|x^{(i)})) \\right) \\\\\n",
    "                        &\\ge \\mathbb{E}_{z} \\left[\\log  p_\\theta (x^{(i)}|z) \\right]\n",
    "                        - D_{KL} \\left(q_\\phi (z|x^{(i)}||p_\\theta (z)) \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus the marginal likelihood can be lower bounded by the last equation, whichis also known as the *variational lower bound*.\n",
    "The first term in the last equation is the log likelihood of the reconstruction from the decoder whereas the second term is the KL divergence of the posterior distribution of the latent embedding from its prior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "img_shape = (3, 32, 32)\n",
    "img_dim  = 3 * 32 * 32\n",
    "latent_dim = 128\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "loader_kwargs = {'num_workers': os.cpu_count()//2, 'pin_memory': True} \n",
    "\n",
    "train_data = datasets.CIFAR10(data_path, transform=transform, train=True, download=True)\n",
    "test_data  = datasets.CIFAR10(data_path, transform=transform, train=False, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, **loader_kwargs)\n",
    "test_loader  = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False, **loader_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "Given an input x, the encoder first maps into the hidden space as\n",
    "$$h_e = ReLU(W_e · x)$$\n",
    "with an affine transform $W_e$.\n",
    "Then $h_e$ is mapped to low dimensional latent features $\\mu$ and $\\log \\sigma^2$ respectively as\n",
    "$$\n",
    "\\mu = W_\\mu \\cdot h_e \\\\\n",
    "\\log \\sigma^2 = W_\\sigma \\cdot h_e\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "        Produces the parameters of normal distribution q, \n",
    "        mean and log of variance.\n",
    "    \"\"\"\n",
    "    def __init__(self, img_channels=3, feature_dim=32*32*32, latent_dim=latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, 16, 3, padding=1),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.FC_mean = nn.Linear(feature_dim, latent_dim)\n",
    "        self.FC_var = nn.Linear(feature_dim, latent_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        mean = self.FC_mean(x)\n",
    "        log_var = self.FC_var(x) \n",
    "        \n",
    "        return mean, log_var\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "Given an sampled latent z, the decoder first maps into the hidden space as\n",
    "$$h_d = ReLU(W_d \\cdot z)$$\n",
    "with an affine transform $W_d$.\n",
    "Then hd is reconstructed into the input image as\n",
    "$$ x' = sigmoid(W_r \\cdot h_d) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, img_channels=3, feature_dim=32*32*32, latent_dim=latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decFC1 = nn.Linear(latent_dim, feature_dim)\n",
    "        self.decConv1 = nn.ConvTranspose2d(32, 16, 3, padding=1)\n",
    "        self.decConv2 = nn.ConvTranspose2d(16, img_channels, 3, padding=1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.decFC1(x))\n",
    "        x = x.view(-1, 32, 32, 32)\n",
    "        x = F.leaky_relu(self.decConv1(x))\n",
    "        x = torch.sigmoid(self.decConv2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reparameterization Trick\n",
    "As taking a derivative of a random sampling is non-trivial, we use the reparameterization trick. In the VAE, it is assumed that $\\mathcal{z}$ follows a Gaussian distribution $\\mathcal{N}(\\mu, \\sigma ^2)$. Taking a derivative with respect to $\\mathcal{N}(\\mu, \\sigma ^2)$ directly is non-trivial. Thus we introduce an auxiliary variable $\\epsilon$ to make it available to take a derivative and use the gradient descent.\n",
    "$$\n",
    "z = \\mu + \\sigma \\odot \\epsilon \\\\\n",
    "\\epsilon ∼ \\mathcal{N}(0, 1)\n",
    "$$\n",
    "This function returns sampled $\\mathcal{z}$ from the given mu and log_var which corresponds to $\\mu$ and $\\log \\sigma ^2$, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "        \n",
    "    def reparam(self, mean, var):\n",
    "        epsilon = torch.randn_like(var)\n",
    "        z = mean + var * epsilon\n",
    "        return z\n",
    "        \n",
    "                \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.Encoder(x)\n",
    "        z = self.reparam(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n",
    "        x_hat = self.Decoder(z)\n",
    "        \n",
    "        return x_hat, mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "\n",
    "model = VAE(Encoder=encoder, Decoder=decoder).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions\n",
    "Our goal is maximizing the right hand side of Equation \n",
    "\n",
    "$$\n",
    "\\max _{\\phi, \\theta} \\mathbb{E}_{z} \\left[\\log p_\\theta (x^{(i)}|z)\\right] - D_{KL}\\left( q_\\phi (z|x^{(i)}) || p_\\theta (z)\\right) \\\\ \n",
    "$$\n",
    "which is equivalent to\n",
    "$$\n",
    "\\min _{\\phi, \\theta} \\mathbb{E}_{z} \\left[-\\log p_\\theta (x^{(i)}|z)\\right] + D_{KL}\\left(q_\\phi (z|x^{(i)}) || p_\\theta (z)\\right) \\\\ \n",
    "$$\n",
    "Assuming that $\\log p_\\theta (x^{(i)}|z)$ follows Bernoulli distribution, the negative log likelihood becomes the binary cross entropy. For the KL divergence, we assume that the prior distribution of $\\mathcal{z}$ is the standard normal distribution. According the the Appendix B of the [Kingma et al., 2013], the KL divergence term becomes as below\n",
    "$$\n",
    "D_{KL}\\left( q_\\phi (z|x^{(i)}) || p_\\theta (z) \\right) = -\\frac{1}{2} \\sum_{i=1}^{J} \\left(1+\\log \\sigma _j^2 -\\mu _j^2 - \\sigma _j^2 \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = F.binary_cross_entropy(x_hat, x, reduction='sum')\n",
    "    KLD = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return reproduction_loss + KLD\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_dir = 'vae_images'\n",
    "os.makedirs(saved_dir, exist_ok= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, loss: -6026667.0000\n",
      "epoch: 2/10, loss: -5808132.5000\n",
      "epoch: 3/10, loss: -5369639.0000\n",
      "epoch: 4/10, loss: -6513082.5000\n",
      "epoch: 5/10, loss: -6273664.0000\n",
      "epoch: 6/10, loss: -5821231.5000\n",
      "epoch: 7/10, loss: -5952860.0000\n",
      "epoch: 8/10, loss: -6387846.0000\n",
      "epoch: 9/10, loss: -5942550.5000\n",
      "epoch: 10/10, loss: -6444833.5000\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        img, label = data\n",
    "        img = img.view(batch_size, *img_shape)\n",
    "        img = img.to(device)\n",
    "\n",
    "        img_hat, mean, log_var = model(img)\n",
    "        loss = loss_function(img, img_hat, mean, log_var)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "    # ===== save images and print logs =====\n",
    "    save_image(img_hat.data[:25], f\"{saved_dir}/{epoch+1}.png\", nrow=5, normalize=True)\n",
    "    print(f'epoch: {epoch+1}/{n_epochs}, loss: {loss.item() :.4f}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
